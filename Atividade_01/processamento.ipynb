{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, http://nexus.olxbr.io/repository/pypi-olx/simple\n",
      "Requirement already satisfied: pyspark in /home/jovyan/.local/lib/python3.8/site-packages (3.3.0)\n",
      "Requirement already satisfied: findspark in /home/jovyan/.local/lib/python3.8/site-packages (2.0.1)\n",
      "Requirement already satisfied: pydeequ==1.0.1 in /home/jovyan/.local/lib/python3.8/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.14.1 in /home/jovyan/.local/lib/python3.8/site-packages (from pydeequ==1.0.1) (1.23.3)\n",
      "Requirement already satisfied: pandas>=0.23.0 in /home/jovyan/.local/lib/python3.8/site-packages (from pydeequ==1.0.1) (1.5.0)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /home/jovyan/.local/lib/python3.8/site-packages (from pyspark) (0.10.9.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23.0->pydeequ==1.0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23.0->pydeequ==1.0.1) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=0.23.0->pydeequ==1.0.1) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark findspark pydeequ==1.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please set env variable SPARK_VERSION\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pydeequ\n",
    "from pydeequ.checks import Check, CheckLevel\n",
    "from pydeequ.verification import VerificationSuite, VerificationResult\n",
    "\n",
    "from pyspark.sql import SparkSession, functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "com.amazon.deequ#deequ added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-4d593b9c-317d-4726-82dc-7f1712ebd75f;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.amazon.deequ#deequ;1.2.2-spark-3.0 in central\n",
      "\tfound org.scalanlp#breeze_2.12;0.13.2 in central\n",
      "\tfound org.scalanlp#breeze-macros_2.12;0.13.2 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.1 in central\n",
      "\tfound com.github.fommil.netlib#core;1.1.2 in central\n",
      "\tfound net.sf.opencsv#opencsv;2.3 in central\n",
      "\tfound com.github.rwl#jtransforms;2.4.0 in central\n",
      "\tfound junit#junit;4.8.2 in central\n",
      "\tfound org.apache.commons#commons-math3;3.2 in central\n",
      "\tfound org.spire-math#spire_2.12;0.13.0 in central\n",
      "\tfound org.spire-math#spire-macros_2.12;0.13.0 in central\n",
      "\tfound org.typelevel#machinist_2.12;0.6.1 in central\n",
      "\tfound com.chuusai#shapeless_2.12;2.3.2 in central\n",
      "\tfound org.typelevel#macro-compat_2.12;1.1.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.5 in central\n",
      ":: resolution report :: resolve 338ms :: artifacts dl 11ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazon.deequ#deequ;1.2.2-spark-3.0 from central in [default]\n",
      "\tcom.chuusai#shapeless_2.12;2.3.2 from central in [default]\n",
      "\tcom.github.fommil.netlib#core;1.1.2 from central in [default]\n",
      "\tcom.github.rwl#jtransforms;2.4.0 from central in [default]\n",
      "\tjunit#junit;4.8.2 from central in [default]\n",
      "\tnet.sf.opencsv#opencsv;2.3 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.2 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.1 from central in [default]\n",
      "\torg.scalanlp#breeze-macros_2.12;0.13.2 from central in [default]\n",
      "\torg.scalanlp#breeze_2.12;0.13.2 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.5 from central in [default]\n",
      "\torg.spire-math#spire-macros_2.12;0.13.0 from central in [default]\n",
      "\torg.spire-math#spire_2.12;0.13.0 from central in [default]\n",
      "\torg.typelevel#machinist_2.12;0.6.1 from central in [default]\n",
      "\torg.typelevel#macro-compat_2.12;1.1.1 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.scala-lang#scala-reflect;2.12.0 by [org.scala-lang#scala-reflect;2.12.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   16  |   0   |   0   |   1   ||   15  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-4d593b9c-317d-4726-82dc-7f1712ebd75f\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 15 already retrieved (0kB/39ms)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Atividade_01\")\n",
    "    .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\n",
    "    .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read\n",
    "    .option(\"delimiter\", \",\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .csv(\"./iris.txt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Schema de Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = Check(spark, CheckLevel.Warning, \"Review Check\")\n",
    "\n",
    "checkResult = (\n",
    "    VerificationSuite(spark)\n",
    "    .onData(df)\n",
    "    .addCheck(\n",
    "        (\n",
    "            check\n",
    "            .isComplete(\"sepal_length\")\n",
    "            .isComplete(\"sepal_width\")\n",
    "            .isComplete(\"sepal_length\")\n",
    "            .isComplete(\"petal_width\")\n",
    "            .isComplete(\"classEncoder\")\n",
    "            .isContainedIn(\"class\", ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])\n",
    "        )\n",
    "    )\n",
    "    .run()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+--------------------+-----------------+------------------+\n",
      "|       check|check_level|check_status|          constraint|constraint_status|constraint_message|\n",
      "+------------+-----------+------------+--------------------+-----------------+------------------+\n",
      "|Review Check|    Warning|     Success|CompletenessConst...|          Success|                  |\n",
      "|Review Check|    Warning|     Success|CompletenessConst...|          Success|                  |\n",
      "|Review Check|    Warning|     Success|CompletenessConst...|          Success|                  |\n",
      "|Review Check|    Warning|     Success|CompletenessConst...|          Success|                  |\n",
      "|Review Check|    Warning|     Success|CompletenessConst...|          Success|                  |\n",
      "|Review Check|    Warning|     Success|ComplianceConstra...|          Success|                  |\n",
      "+------------+-----------+------------+--------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "checkResult_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrando dados validos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = (\n",
    "    df\n",
    "    .filter(\n",
    "        (df.sepal_length >= 4.3) & (df.sepal_length <= 7.9)\n",
    "    )\n",
    "    .filter(\n",
    "        (df.sepal_width >= 2.0) & (df.sepal_width <= 4.4)\n",
    "    )\n",
    "    .filter(\n",
    "        (df.petal_length >= 1.0) & (df.petal_length <= 6.9)\n",
    "    )\n",
    "    .filter(        \n",
    "        (df.petal_width >= 0.1) & (df.petal_width <= 3.5)\n",
    "    )\n",
    "    .filter(\n",
    "        (df.classEncoder >= 0) & (df.classEncoder <= 2)\n",
    "    )\n",
    "    .filter(\n",
    "        df['class'].isin(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Salvando dados validos\n",
    "(\n",
    "    df_valid\n",
    "    .repartition(1)\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(\"./iris-valid-data\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados Invalidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invalid = df.exceptAll(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invalid = df_invalid.withColumn(\n",
    "    \"messageError\",\n",
    "    F.when(\n",
    "        df.sepal_length <= 4.3, \"sepal_length menor que 4.3\"\n",
    "    ).when(\n",
    "        df.sepal_length >= 7.9, \"sepal_length maior que 7.9\"\n",
    "    ).when(\n",
    "        df.sepal_width <= 2.0, \"sepal_width menor que 2.0\"\n",
    "    ).when(\n",
    "        df.sepal_width >= 4.4, \"sepal_width maior que 4.4\"\n",
    "    ).when(\n",
    "        df.petal_length <= 1.0, \"petal_length menor que 1.0\"\n",
    "    ).when(\n",
    "        df.petal_length >= 6.9, \"petal_length maior que 6.9\"\n",
    "    ).when(\n",
    "        df.petal_width <= 0.1, \"petal_width menor que 0.1\"\n",
    "    ).when(\n",
    "        df.petal_width >= 3.5, \"petal_width maior que 3.5\"\n",
    "    ).when(\n",
    "        df.classEncoder <= 0, \"classEncoder menor que 0\"\n",
    "    ).when(\n",
    "        df.classEncoder >= 2, \"classEncoder maior que 2\"\n",
    "    ).otherwise(\n",
    "        \"class não esta é 'Iris-setosa', 'Iris-versicolor' ou 'Iris-virginica'\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_invalid\n",
    "    .repartition(1)\n",
    "    .write\n",
    "    .option(\"header\", \"true\")\n",
    "    .mode(\"overwrite\")\n",
    "    .csv(\"./iris-invalid-data\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
